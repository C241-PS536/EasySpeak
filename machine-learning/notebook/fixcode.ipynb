{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "import splitfolders\n",
    "\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "from PIL import Image\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data\n",
    "The data set is a collection of images of alphabets from BISINDO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imageDataset = 'DataFix'\n",
    "\n",
    "paths = [path.parts[-2:] for path in\n",
    "         Path(imageDataset).rglob('*.*')]                             #writing purpose ('*.*') so that all image formats can be retrieved\n",
    "df = pd.DataFrame(data=paths, columns=['Class','Images'])     #create column names for dataframe\n",
    "df = df.sort_values('Class',ascending=True)                   #sort class name\n",
    "df.reset_index(drop=True, inplace=True)                       #sort index of each row\n",
    "df "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View the total class and the amount of data for each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "totalImage = len(df.Images)\n",
    "totalClass = len(df['Class'].value_counts())\n",
    "\n",
    "print(\"Total Image : {}\" .format(totalImage))\n",
    "print(\"Total Class : {}\" .format(totalClass))\n",
    "\n",
    "print('Number of images in each class : ')\n",
    "print(df['Class'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the size of each image from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def storeImageSize(dataset_path):\n",
    "    image_sizes = []\n",
    "\n",
    "    # Iterate over all folders in the dataset directory\n",
    "    for alphabet_folder in os.listdir(dataset_path):\n",
    "        alphabet_folder_path = os.path.join(dataset_path, alphabet_folder)\n",
    "        \n",
    "        # Check if the current path is a directory\n",
    "        if os.path.isdir(alphabet_folder_path):\n",
    "            # Iterate over all files in the current alphabet folder\n",
    "            for filename in os.listdir(alphabet_folder_path):\n",
    "                file_path = os.path.join(alphabet_folder_path, filename)\n",
    "                \n",
    "                # Check if the file is an image\n",
    "                if filename.lower().endswith(('.jpg')):\n",
    "                    try:\n",
    "                        # Open the image\n",
    "                        with Image.open(file_path) as img:\n",
    "                            # Append the image size to the list\n",
    "                            image_sizes.append(img.size)\n",
    "                    except Exception as e:\n",
    "                        print(f\"Could not open image {filename}: {e}\")\n",
    "    return image_sizes\n",
    "\n",
    "def countsImageSize(image_sizes):\n",
    "    # Count the occurrences of each image size\n",
    "    size_counts = Counter(image_sizes)\n",
    "    \n",
    "    # Extract the sizes and their counts\n",
    "    sizes = list(size_counts.keys())\n",
    "    counts = list(size_counts.values())\n",
    "    \n",
    "    # Convert sizes to string format for better readability in the plot\n",
    "    sizes_str = [f\"{size[0]}x{size[1]}\" for size in sizes]\n",
    "    \n",
    "    # Create a DataFrame for the table\n",
    "    df = pd.DataFrame({\n",
    "        'Image Size (width x height)': sizes_str,\n",
    "        'Number of Images': counts\n",
    "    })\n",
    "    \n",
    "    df = df.sort_values(by='Number of Images', ascending=False)\n",
    "    \n",
    "    # Print the table\n",
    "    print(df)\n",
    "\n",
    "\n",
    "# Get image sizes\n",
    "image_sizes = storeImageSize(imageDataset)\n",
    "\n",
    "# Plot image size counts and display the table\n",
    "countsImageSize(image_sizes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize sample images from each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def displaySampleImage(root_folder):\n",
    "    # Create a list to store image paths\n",
    "    image_paths = []\n",
    "    letters = []\n",
    "\n",
    "    # Iterate over all alphabet folders in the root folder\n",
    "    for letter_folder in sorted(os.listdir(root_folder)):\n",
    "        letter_path = os.path.join(root_folder, letter_folder)\n",
    "        \n",
    "        if os.path.isdir(letter_path):\n",
    "            # Get a list of all image files in the folder\n",
    "            image_files = sorted([\n",
    "                f for f in os.listdir(letter_path) \n",
    "                if f.lower().endswith(('.png', '.jpg', '.jpeg', '.gif', '.bmp'))\n",
    "            ])\n",
    "            \n",
    "            if image_files:\n",
    "                # Select the first image in the folder\n",
    "                first_image = image_files[0]\n",
    "                image_paths.append(os.path.join(letter_path, first_image))\n",
    "                letters.append(letter_folder)\n",
    "    \n",
    "    # Calculate the number of rows and columns for the plot\n",
    "    num_images = len(image_paths)\n",
    "    cols = 4\n",
    "    rows = (num_images // cols) + (1 if num_images % cols != 0 else 0)\n",
    "    \n",
    "    # Create a figure to display the images\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(15, 5 * rows))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    # Display each image\n",
    "    for i, img_path in enumerate(image_paths):\n",
    "        img = Image.open(img_path)\n",
    "        axes[i].imshow(img)\n",
    "        axes[i].axis('off')\n",
    "        axes[i].set_title(letters[i])\n",
    "    \n",
    "    # Remove any empty subplots\n",
    "    for j in range(i + 1, len(axes)):\n",
    "        fig.delaxes(axes[j])\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Display one image per letter\n",
    "displaySampleImage(imageDataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resize Image to 128x128 Pixel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resizeImage(root_folder, target_folder, size=(128, 128)):\n",
    "    # Supported image formats\n",
    "    supported_formats = ('.png', '.jpg', '.jpeg', '.gif', '.bmp')\n",
    "\n",
    "    # Iterate over all folders and files in the root folder recursively\n",
    "    for root, dirs, files in os.walk(root_folder):\n",
    "        for file in files:\n",
    "            if file.lower().endswith(supported_formats):\n",
    "                # Construct full file path\n",
    "                file_path = os.path.join(root, file)\n",
    "                \n",
    "                # Determine the relative path inside the root folder\n",
    "                relative_path = os.path.relpath(root, root_folder)\n",
    "                \n",
    "                # Construct target folder path\n",
    "                target_subfolder = os.path.join(target_folder, relative_path)\n",
    "                if not os.path.exists(target_subfolder):\n",
    "                    os.makedirs(target_subfolder)\n",
    "                \n",
    "                # Open the image\n",
    "                with Image.open(file_path) as img:\n",
    "                    # Resize the image\n",
    "                    resized_img = img.resize(size, Image.ANTIALIAS)\n",
    "                    \n",
    "                    # Construct target file path\n",
    "                    target_file_path = os.path.join(target_subfolder, file)\n",
    "                    \n",
    "                    # Save the resized image\n",
    "                    resized_img.save(target_file_path)\n",
    "\n",
    "                #print(f\"Resized and saved {file_path} to {target_file_path}\")\n",
    "\n",
    "# Path to the root folder containing images\n",
    "rootFolder = 'DataFix'\n",
    "\n",
    "# Path to the target folder to save resized images\n",
    "targetFolder = 'ResizedData'\n",
    "\n",
    "# Resize images to 128x128 and save them with the same folder structure\n",
    "resizeImage(rootFolder, targetFolder, size=(128, 128))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converts resized data to grayscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processImage(input_path, output_path):\n",
    "    # Read the image\n",
    "    img = cv2.imread(input_path)\n",
    "    \n",
    "    # Convert the image to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Save the grayscale image\n",
    "    cv2.imwrite(output_path, gray)\n",
    "\n",
    "def processFolder(input_folder, output_folder):\n",
    "    # Iterate through each folder in the input folder\n",
    "    for folder_name in sorted(os.listdir(input_folder)):\n",
    "        folder_path = os.path.join(input_folder, folder_name)\n",
    "        \n",
    "        # Check if the item is a folder\n",
    "        if os.path.isdir(folder_path):\n",
    "            # Create corresponding output folder if it doesn't exist\n",
    "            output_subfolder = os.path.join(output_folder, folder_name)\n",
    "            if not os.path.exists(output_subfolder):\n",
    "                os.makedirs(output_subfolder)\n",
    "            \n",
    "            # Process images in the subfolder\n",
    "            for filename in sorted(os.listdir(folder_path)):\n",
    "                if filename.endswith(('.png', '.jpg', '.jpeg')):\n",
    "                    input_path = os.path.join(folder_path, filename)\n",
    "                    output_path = os.path.join(output_subfolder, filename)\n",
    "                    processImage(input_path, output_path)\n",
    "\n",
    "# Define input and output folders\n",
    "inputFolder = 'ResizedData'\n",
    "outputFolder = 'GrayScale'\n",
    "\n",
    "# Process the folder structure\n",
    "processFolder(inputFolder, outputFolder)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Dataset into 3 Directory for Train, Validation, and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying files: 5980 files [00:18, 316.34 files/s]\n"
     ]
    }
   ],
   "source": [
    "splitfolders.ratio('GrayScale',output='SplitData', seed=1333, ratio=(0.8,0.1,0.1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation with ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4784 images belonging to 26 classes.\n",
      "Found 598 images belonging to 26 classes.\n",
      "Found 598 images belonging to 26 classes.\n"
     ]
    }
   ],
   "source": [
    "# ImageDataGenerator\n",
    "traindir = 'SplitData/train'\n",
    "testdir = 'SplitData/test'\n",
    "valdir = 'SplitData/val'\n",
    "\n",
    "training_datagen = ImageDataGenerator(\n",
    "        rescale = 1./255,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        fill_mode='nearest')\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale= 1. / 255)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "\n",
    "train_generator = training_datagen.flow_from_directory(\n",
    "\ttraindir,\n",
    "\ttarget_size=(128,128),\n",
    "\tclass_mode='categorical',\n",
    "  batch_size=128\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(directory= valdir, \n",
    "                                         target_size=(128, 128), \n",
    "                                         batch_size = 128)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "\ttestdir,\n",
    "\ttarget_size=(128,128),\n",
    "\tclass_mode='categorical',\n",
    "  batch_size=128,\n",
    "  shuffle= False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3,3), activation='relu', padding='same', input_shape=(128, 128, 1)),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(32, (3,3), activation='relu', padding='same'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu', padding='same'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu', padding='same'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "\n",
    "    tf.keras.layers.Conv2D(128, (3,3), activation='relu', padding='same'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(128, (3,3), activation='relu', padding='same'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "\n",
    "    tf.keras.layers.Flatten(),\n",
    "\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    \n",
    "    tf.keras.layers.Dense(26, activation='softmax')\n",
    "])\n",
    "\n",
    "# Print the model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile and Fit the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'categorical_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_generator, epochs=100, validation_data = val_generator, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend(loc=0)\n",
    "plt.figure()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.predict(test_generator,verbose = 0)\n",
    "\n",
    "y_pred = np.argmax(result, axis = 1)\n",
    "\n",
    "y_true = test_generator.labels\n",
    "\n",
    "# Evaluvate\n",
    "loss,acc = model.evaluate(test_generator,verbose = 0)\n",
    "\n",
    "print('The accuracy of the model for testing data is:',acc*100)\n",
    "print('The Loss of the model for testing data is:',loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = y_pred\n",
    "y = y_true\n",
    "correct = np.nonzero(p==y)[0]\n",
    "incorrect = np.nonzero(p!=y)[0]\n",
    "\n",
    "print(\"Correct predicted classes:\",correct.shape[0])\n",
    "print(\"Incorrect predicted classes:\",incorrect.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(test_generator.classes, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(test_generator.classes, predictions)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(test_generator.classes, predictions)\n",
    "sns.heatmap(cm, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"modelFix.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
